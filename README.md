# microseg-vision

[![CI](https://github.com/huang3527/microseg-vision/actions/workflows/ci.yml/badge.svg)](https://github.com/huang3527/microseg-vision/actions/workflows/ci.yml)
[![Coverage](https://codecov.io/gh/huang3527/microseg-vision/branch/main/graph/badge.svg)](https://codecov.io/gh/huang3527/microseg-vision)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-red.svg)
![Status](https://img.shields.io/badge/Status-Active-success.svg)

---

<p align="center">
  <img src="https://raw.githubusercontent.com/pytorch/pytorch/main/docs/source/_static/img/pytorch-logo-dark.png" width="160">
</p>

<p align="center">
<b>A clean, minimal, and production-ready PyTorch pipeline for 2D image segmentation.</b><br>
Designed for reproducible research, professional portfolio, and educational tutorials.
</p>

---

## ğŸš€ Features

- ğŸ“ Simple **folder-based segmentation dataset** (`images/` + `masks/`)
- ğŸ”„ Modular **Transforms** (Resize, H/V Flip, Normalize, ToTensor)
- ğŸ§  Clean **UNet implementation** in pure PyTorch
- âš™ï¸ **YAML config system** for experiment reproducibility
- ğŸ‹ï¸ **Trainer** with validation metrics (Dice/IoU/Pixel Accuracy)
- ğŸ–¼ **InferenceEngine** for single images or whole folders
- ğŸ“¦ Publish-ready project structure (`pyproject.toml`, MIT License)
- ğŸ”§ GitHub Actions CI (lint, test, style)
- ğŸ“Š Optional Codecov coverage support

---

## ğŸ“˜ Example: Training on Kvasir-SEG (public dataset)

The **Kvasir-SEG** dataset contains 1,000+ colonoscopy images with masks.  
It is fully open-source and ideal for demonstrating segmentation pipelines.

Dataset link:  
https://datasets.simula.no/kvasir-seg/

---

### 1. Prepare Data

mkdir -p data/train data/val

Place data into:
data/
  train/
    images/
    masks/
  val/
    images/
    masks/

### 2. Train
python -m microseg.train --config configs/unet_example.yaml

Results + checkpoints will be saved to:
runs/example/checkpoints/best.pt

### 3. Inference

python -m microseg.infer \
  --config configs/unet_example.yaml \
  --checkpoint runs/example/checkpoints/best.pt \
  --input_folder path/to/images \
  --output_folder path/to/output_masks

The output masks will be saved as binary .png.

### ğŸ“‚ Project Structure

microseg-vision/
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ unet_example.yaml
â”œâ”€â”€ experiments/
â”‚   â””â”€â”€ notebooks/
â”‚       â””â”€â”€ demo.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ microseg/
â”‚       â”œâ”€â”€ data.py
â”‚       â”œâ”€â”€ transforms.py
â”‚       â”œâ”€â”€ models.py
â”‚       â”œâ”€â”€ metrics.py
â”‚       â”œâ”€â”€ train.py
â”‚       â””â”€â”€ infer.py
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_import.py
â”œâ”€â”€ .github/workflows/ci.yml
â”œâ”€â”€ LICENSE
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â””â”€â”€ Makefile

### ğŸ›  Development

make install
make lint
make test
make train
make infer

### ğŸ§ª Coverage

Install extra tools:
pip install pytest-cov codecov

Run:
pytest --cov=src/microseg --cov-report=xml

Upload coverage (GitHub Actions does this automatically):
codecov

###  ğŸ“œ License

MIT License â€” You are free to use, modify, and distribute this project.

### â­ Acknowledgments

	â€¢	Kvasir-SEG dataset (Simula)
	â€¢	PyTorch team
	â€¢	Open-source contributors